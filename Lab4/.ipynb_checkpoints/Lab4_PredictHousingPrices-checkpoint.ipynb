{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Predicting Housing Prices with Linear Regression ðŸ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* Understanding and Applying Linear Regression \n",
    "* Data Exploration\n",
    "* Practice ML Workflow: Training, Testing, and Evaluation\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Implementing Linear Regression](#1.-Implementing-Linear-Regression)\n",
    "2. [Finding a House in Boston](#2.-Finding-a-House-in-Boston)\n",
    "3. [Exploring the Data](#3.-Exploring-the-Data)\n",
    "4. [Training the Model](#4.-Training-the-Model)\n",
    "    5. [Making Training and Test Datasets](#Making-Training-and-Test-Datasets)\n",
    "    6. [Regression on Boston Housing data](#Regression-on-Boston-Housing-data)\n",
    "5. [Analyzing Model Performance](#5.-Analyzing-Model-Performance)\n",
    "    7. [Root Mean Squared Error (RMSE)](#Root-Mean-Squared-Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In this lab, you will build your first intelligent application that makes predictions from data. We will explore this idea within the context of our first case study, predicting house prices, where you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms, etc.). This is just one of the many places where regression can be applied. Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression. You will also examine how to analyze the performance of your predictive model and implement regression in practice using an iPython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Regression?\n",
    "\n",
    "Let's start our discussion with the idea of **regression** itself. It's [Wikipedia article](https://en.wikipedia.org/wiki/Regression_analysis) starts with this:\n",
    "\n",
    "> In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables.\n",
    "\n",
    "The goal is to take a set of predictor variables, or _features_, and figure out how they contribute to the phenomenon we are interested. Again from Wikipedia, regression\n",
    "\n",
    "> helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the [predictor] independent variables is varied while the others...are held fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is typically achieved by combining features with a **model**, a simple representation of the relationships between features. In the case of linear regression, we use a **linear model**, $$y = wx + b,$$ which combines the features, $x$, after weighting each by their significance, $w$, and adding a bias value, $b$, to compute the predicted value, $y$. In this case, $d$ is the number of features we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put (slightly more) simply, **linear regression** tries to model the relationship between features and a phenomenon variable by fitting a line to observed data. ![Linear Regression](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/2560px-Linear_regression.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start working on the Boston housing data set, we will first use the toy dataset from class to develop and test our code. The dataset is stored in a `txt` file so we have to import it first. Using this small toy dataset, we will implement a simple linear regression model that use $x$ as predictor and $y$ as target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x, y = np.loadtxt('utility/data/toy_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16,9]\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving Model Parameters\n",
    "\n",
    "Recall the derivation of $w$ and $b$ from lecture minimizing the sum of squared error, also residual sum of squares (RSS), with slight rearrangement:\n",
    "\n",
    "\n",
    "$$b = \\displaystyle \\frac{1}{n} \\sum_{n=1}^n y_i - w \\frac{1}{n} \\sum_{n=1}^n x_i $$\n",
    "\n",
    "and\n",
    "\n",
    "$$w = \\frac{\\displaystyle\\sum_{n=1}^n x_iy_i - \\frac{1}{n} \\sum_{n=1}^n x_i \\sum_{n=1}^n y_i}{\\displaystyle\\sum_{n=1}^n x_i^2 - \\frac{1}{n} \\sum_{n=1}^n x_i \\sum_{n=1}^n x_i}$$\n",
    "\n",
    "This is equivalent to: \n",
    "\n",
    "$$w = \\frac{\\displaystyle \\frac{1}{n}\\sum_{n=1}^n x_iy_i - \\frac{1}{n} \\sum_{n=1}^n x_i \\frac{1}{n} \\sum_{n=1}^n y_i}{\\displaystyle \\frac{1}{n} \\sum_{n=1}^n x_i^2 - \\bar{x}^2} = ... = \\frac{\\displaystyle \\frac{1}{n}\\sum_{n=1}^n (x_i - \\bar{x}) (y_i - \\bar{y}) }{\\displaystyle \\frac{1}{n} \\sum_{n=1}^n (x_i - \\bar{x})^2} = \\frac{\\displaystyle \\frac{1}{n-1}\\sum_{n=1}^n (x_i - \\bar{x}) (y_i - \\bar{y}) }{\\displaystyle \\frac{1}{n-1} \\sum_{n=1}^n (x_i - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}$$\n",
    "\n",
    "Note that now the denominator the _sample variance_ as introduced in lecture 2 (EDA) and the numerator is the _sample covariance_ (which essentially extends the notion of variance to two random variables). \n",
    "\n",
    "To get to the last expression we essentailly multiply both numberator and denominator by $\\frac{n}{n-1}$. This turns the estimators into _unbiased_ estimators. Discussing biased versus unbiased estimators goes beyond the scope of this course. (Watch out for an explanation once you take a course on Probability and Statistics!)\n",
    "\n",
    "> **Homework**: Verify that you can derive the above equations yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Regression Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement these formulas. Do **not** use for loops!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** First, let's start with `covariance`. Remember that $$\\text{Cov(x, y)} = \\displaystyle \\frac{1}{n-1} \\sum_{n=1}^n (x_i - \\bar x)(y_i - \\bar y)$$\n",
    "\n",
    "Assign the result of your computation to `cov`, which is returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y):\n",
    "    '''computes the sample covariance of X and Y given the formula above'''\n",
    "    \n",
    "    assert x.shape == y.shape, 'dimensions of X and Y should match in 1D linear regression'\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    cov = \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Next, implement `variance`. Remember that $$\\text{Var(x)} = \\displaystyle \\frac{1}{n-1} \\sum_{n=1}^n (x_i - \\bar x)^2$$\n",
    "\n",
    "Assign the result of your computation to `var`, which is returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(x):\n",
    "    '''computes the sample variance of observations X given the formula above'''\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Next, implement `fit`. This function computes the best-fitting model parameters $w$ and $b$. Refer back to the derivation from above. Assign the result of your computation to variables `w` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y):\n",
    "    '''computes model parameters W and B that best-fit observation data X and Y'''\n",
    "    \n",
    "    assert x.shape == y.shape, 'dimensions of X and Y should match in 1D linear regression'\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    assert np.isscalar(w) and np.isscalar(b), 'W and B should be scalars in 1D linear regression'\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Finally, implement `predict`. This function computes the predicted values of the model given $w$, $b$, and points $x$. Refer back to the derivation from above. Assign the result of your computation to variables `w` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, x):\n",
    "    '''computes the predicted values of X given model parameters W and B'''\n",
    "    \n",
    "    assert np.isscalar(w) and np.isscalar(b), 'W and B should be scalars in 1D linear regression'\n",
    "    if not isinstance(x, int):\n",
    "        assert len(x.shape) == 1, 'X should be an int or n x 1 array'\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your implementation you can use our example from the lecture. My house, which has 1500sqft should be worth $359k (rounded). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = fit(x, y)\n",
    "\n",
    "x_myhouse = 1500\n",
    "y_myhouse = predict(w, b, x_myhouse)\n",
    "\n",
    "print(f'My house is worth ${y_myhouse:0.0f},000.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Regression Model (Fitted Line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with 1000 equally spaced values in the range 0 to x.max\n",
    "x_star = np.linspace(0, x.max(), 1000)\n",
    "\n",
    "# get the predictions for each of those values\n",
    "y_star = predict(w, b, x_star)\n",
    "\n",
    "# plot the points using a scatter plot (note this is not a line... it just looks like one)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x_star, y_star, color=\"orange\")\n",
    "plt.title('LM of Toy Data')\n",
    "plt.xlabel(\"Size in sq. ft.\")\n",
    "plt.ylabel(\"Price in 1k USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding a House in Boston\n",
    "\n",
    "I hear that you're trying to find a house in Boston! As excited as you are to go look at some houses, I bet the data scientist inside you can't resist the urge to do some good-ol' market research first.\n",
    "\n",
    "Okay, so maybe you're not looking to find a house in Boston, but there are many people who are interested in understanding the housing market there. More and more, professionals in various industries are turning to data science to better understanding trends in their fields. Let's give it a shot!\n",
    "\n",
    "![boston housing](https://cdn10.bostonmagazine.com/wp-content/uploads/sites/2/2014/11/homesforsale.jpg)\n",
    "Image sourced from [Boston Magazine](https://www.bostonmagazine.com/property/2014/11/06/open-houses-11-7/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing the Problem\n",
    "\n",
    "As we discussed in Lab 1, the data science workflow we will follow in this class begins with developing a question. For this example, let's go with this:\n",
    "\n",
    "> _Can we identify any patterns and trends in the Boston housing market? And, if so, can we build a model to predict the price of a house given some of its specs?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** What other kinds of questions would be interesting to ask about this dataset? Discuss with your neighbors and record your discussion in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring the Data\n",
    "\n",
    "In the field, you will often have to collect and process the data you need on your own. In this case, however, we will be using data that has already been collected and cleaned. The cell below downloads the dataset hosted by [Scikit Learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston() \n",
    "\n",
    "# check if dataset is correctly loaded\n",
    "print(f'''The loaded dataset contains\n",
    "    {boston.data.shape[0]} observations and\n",
    "    {boston.data.shape[1]} features per observation.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our raw data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHOA. This looks crazy! Let's try to better understand our data by looking at its components. Luckily, a lot of this data is already organized for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Things in Order\n",
    "\n",
    "The dataset for this project originates from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). The Boston housing data was collected in 1978 and each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts. Run the cell blow to see the names and a short description for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this data and put it into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(boston.data)\n",
    "y = np.array(boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Evaluate `X` and `y` to see what they look like. Also, try checking their shapes. What do the values correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Data\n",
    "After the dataset is loaded, we will make a cursory investigation about the Boston housing data and provide your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(16, 16))\n",
    "f.subplots_adjust(hspace=0.6)\n",
    "\n",
    "# visualize the relationship of all varaibles and the price (y-axis)\n",
    "for index, feature_name in enumerate(boston.feature_names):\n",
    "    ax = f.add_subplot(5, 3, index + 1)\n",
    "    ax.scatter(boston.data[:, index], boston.target, s=0.5)\n",
    "    ax.set_title(feature_name)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** Take a look at all the scatter plots, disuss the following with your neighbor:\n",
    "1. If you can only choose one feature as predictor in the model, which one will you choose, and why?\n",
    "2. Try to find all features are that negatively correlated with price. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "Now, you will train the regression model and then use it to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Training and Test Datasets\n",
    "We can **split the dataset** into two sets so that the model can be trained and tested on different data.\n",
    "Testing accuracy is a better estimate than training accuracy of out-of-sample performance. We usually split the dataset so that the testing portion is smaller than the training portion. An 80/20 split is generally a safe bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N = len(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "#Check the split is successful\n",
    "print(f'{100 * X_train.shape[0] / N:0.2f}% of data in training set')\n",
    "print(f'{100 * X_test.shape[0] / N:0.2f}% of data in test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are approximately 80% training and 20% testing, so split is successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression on Boston Housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to implement the function we previously wrote on the larger boston dataset. Note that we are only using the training portion of the data so we can later evaluate our model performance using the testing data. Let's try building a model that regresses `PRICE` on to the feature that you selected in the write up earlier.\n",
    "\n",
    "**Try this!** In the following cell, set your chosen feature label (string) to the variable `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# retrieve the index of the supplied target\n",
    "target_index = boston.feature_names.tolist().index(target)\n",
    "\n",
    "# Extract feature of interest from training dataest\n",
    "X_train_target = X_train[:, target_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have isolated the target feature, let's build a model with the functions we have already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train mdoel on X_train_target (training inputs) and y_train (training observations)\n",
    "\n",
    "# your code here\n",
    "\n",
    "print(f'w = {w}, b = {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recycling our previous plotting code from our toy implementation, we can see our regression model against a scatter of our data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with 1000 equally spaced values in the range 0 to x.max\n",
    "x_star = np.linspace(0, X_train_target.max(), 1000)\n",
    "\n",
    "# get the predictions for each of those values\n",
    "y_star = predict(w, b, x_star)\n",
    "\n",
    "# plot the points using a scatter plot (note this is not a line... it just looks like one)\n",
    "plt.scatter(X_train_target, y_train)\n",
    "plt.plot(x_star, y_star, color=\"orange\")\n",
    "plt.xlabel(target)\n",
    "plt.ylabel(\"price in 1k USD\")\n",
    "plt.ylim(0, y_star.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** What do you think of this model? Try this process again on a different predictor (feature) and write about how it compares in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Model Performance\n",
    "\n",
    "It is difficult to measure the quality of a given model without quantifying its performance over training and testing. In this section, you will see some common methods we used to evaluate the performance of a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error\n",
    "\n",
    "Recall from our derivation in lecture that our linear regression model minimizes the **residual sum of squares (RSS)**. $$\\text{RSS} = \\displaystyle \\sum_{i=1}^n (y_i - \\hat f(x_i)), $$where $\\hat f(x)$ is our trained predictor. A common way to measure model performance is to compute the scaled RSS or **mean squared error (MSE)**. $$\\text{MSE} = \\displaystyle \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat f(x_i))$$\n",
    "\n",
    "Taking things a step further, we can report this metric in the original units (eg. thousands of dollars) by simply taking the square root to get **root mean squared error (RMSE)**. $$\\text{RMSE} = \\displaystyle \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat f(x_i))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, we will compute the mean of the squared differences between the actual value and the predicted value, and take the square root. The function is provided in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_test_target = X_test[:, target_index] \n",
    "\n",
    "# Predict y_pred for X_test_target (test inputs)\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "# Evaluate predictions\n",
    "rmse = np.sqrt(mean_squared_error(y_test, Y_pred))\n",
    "f'RMSE: {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is regarded as a measure of the quality of an estimatorâ€”it is always non-negative (we are computing squares), and values closer to zero are better (this suggests the predicted values are closer to the actual value). \n",
    "\n",
    "**Write-up!** Why do we use different datasets to train and evaluate the model? Discuss with your neighbors."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model, Training, and Test Data\n",
    "To wrap up, let's plot our model with both our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the points using a scatter plot (note this is not a line... it just looks like one)\n",
    "ax1 = plt.scatter(X_train_target, y_train, color='gray', alpha=0.5)\n",
    "ax2 = plt.scatter(X_test_target, y_test, marker='o', color='green')\n",
    "ax3, = plt.plot(x_star, y_star, color=\"orange\")\n",
    "plt.xlabel(target)\n",
    "plt.ylabel(\"price in 1k USD\")\n",
    "plt.ylim(0, y_star.max())\n",
    "plt.legend((ax1, ax2, ax3), ('Training data', 'Testing Data', 'Model'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
